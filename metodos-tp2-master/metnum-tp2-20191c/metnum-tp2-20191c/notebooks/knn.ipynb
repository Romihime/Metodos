{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis con KNN\n",
    "## Clasificador en C++ ðŸ’ªðŸ’ª\n",
    "Vamos a probar a nuestro bichito\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los path al ejecutable de python 3.6 y sus librerÃ­as,\n",
    "de acuerdo al virtual env que estÃ©n corriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜buildâ€™: File exists\n",
      "-- The C compiler identification is GNU 5.5.0\n",
      "-- The CXX compiler identification is GNU 5.5.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "Release mode\n",
      "-- Found PythonInterp: /home/luis/miniconda3/bin/python (found version \"3.6.5\") \n",
      "-- Found PythonLibs: /home/luis/miniconda3/lib/libpython3.6m.so\n",
      "-- pybind11 v2.3.dev0\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "CMAKE_INSTALL_PREFIX=/home/luis/dev/metodos-tp2/metnum-tp2-20191c/metnum-tp2-20191c\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/luis/dev/metodos-tp2/metnum-tp2-20191c/metnum-tp2-20191c/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target sentiment\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/sentiment.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/eigen.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module sentiment.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] Built target sentiment\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /home/luis/dev/metodos-tp2/metnum-tp2-20191c/metnum-tp2-20191c/notebooks/sentiment.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!cd .. && git submodule init\n",
    "!cd .. && git submodule update\n",
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luis/dev/metodos-tp2/metnum-tp2-20191c/metnum-tp2-20191c/notebooks\n",
      "Python 3.6.5 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "# Verifico la correcta instalaciÃ³n. Si no falla el import estÃ¡ OK\n",
    "!pwd\n",
    "!python --version\n",
    "import sentiment\n",
    "from sentiment import entrenar\n",
    "from sentiment import generate_vocabulary\n",
    "from sentiment import entrenar_varios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./._imdb_small.csv\n",
      "imdb_small.csv\n",
      "Cantidad de documentos: 12500\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "!cd ../data && tar -xvf *.tgz\n",
    "\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "print(\"Cantidad de documentos: {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>12469</td>\n",
       "      <td>2</td>\n",
       "      <td>12085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>test</td>\n",
       "      <td>Aside from the horrendous acting and the ridic...</td>\n",
       "      <td>neg</td>\n",
       "      <td>11457_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6275</td>\n",
       "      <td>2</td>\n",
       "      <td>6322</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type                                             review  label  \\\n",
       "count   12500                                              12500  12500   \n",
       "unique      2                                              12469      2   \n",
       "top      test  Aside from the horrendous acting and the ridic...    neg   \n",
       "freq     6275                                                  2   6322   \n",
       "\n",
       "                file  \n",
       "count          12500  \n",
       "unique         12085  \n",
       "top     11457_10.txt  \n",
       "freq               2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 6225\n",
      "Cantidad de instancias de test = 6275\n"
     ]
    }
   ],
   "source": [
    "text_train = df[df.type == 'train'][\"review\"]\n",
    "label_train = df[df.type == 'train'][\"label\"]\n",
    "text_test = df[df.type == 'test'][\"review\"]\n",
    "label_test = df[df.type == 'test'][\"label\"]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particion_criticas_equilibradas(text_train, label_train, cant_elems):\n",
    "    dict_texto = text_train.to_dict()\n",
    "    dict_label = label_train.to_dict()\n",
    "    claves_positivos = [x for x in dict_label if dict_label[x] == 'pos']\n",
    "    claves_negativos = [x for x in dict_label if dict_label[x] == 'neg']\n",
    "    posiciones_elegidas_pos = random.sample(range(0, len(claves_positivos)), int(cant_elems/2))\n",
    "    posiciones_elegidas_neg = random.sample(range(0, len(claves_negativos)), int(cant_elems/2))\n",
    "    nuevo_text_train = {}\n",
    "    nuevo_label_train = {}\n",
    "    for i in posiciones_elegidas_pos:\n",
    "        nuevo_label_train[claves_positivos[i]] = 'pos'\n",
    "        nuevo_text_train[claves_positivos[i]] = dict_texto[claves_positivos[i]]\n",
    "    for i in posiciones_elegidas_neg:\n",
    "        nuevo_label_train[claves_negativos[i]] = 'neg'\n",
    "        nuevo_text_train[claves_negativos[i]] = dict_texto[claves_negativos[i]]\n",
    "    return pd.Series(nuevo_text_train), pd.Series(nuevo_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance : 0.49493975903614457 pos 0.5050602409638554 neg\n"
     ]
    }
   ],
   "source": [
    "print(\"Class balance : {} pos {} neg\".format(\n",
    "    (label_train == 'pos').sum() / label_train.shape[0], \n",
    "    (label_train == 'neg').sum() / label_train.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary content:\n",
      " {'ll': 60, 'know': 55, 'br': 13, 'just': 53, 'new': 74, 'time': 105, 'right': 88, 'probably': 84, 'worst': 119, 'film': 35, 've': 110, 'seen': 96, 'acting': 1, 'characters': 16, 'looking': 63, 'films': 36, 'really': 87, 'takes': 100, 'make': 67, 'look': 62, 'music': 73, 'scene': 92, 'believe': 8, 'better': 10, 'pretty': 83, 'especially': 30, 'actors': 4, '10': 0, 'director': 24, 'say': 91, 'making': 69, 'don': 27, 'want': 111, 'kind': 54, 'movies': 72, 'woman': 116, 'does': 25, 'like': 58, 'actor': 3, 'character': 15, 'great': 45, 'story': 98, 'far': 33, 'main': 66, 'did': 22, 'wasn': 112, 'old': 75, 'years': 121, 'times': 106, 'end': 28, 'tv': 109, 'sure': 99, 'good': 43, 'man': 70, 'way': 115, 'saw': 90, 'think': 103, 'point': 82, 'people': 77, 'played': 80, 'let': 56, 'role': 89, 'didn': 23, 'got': 44, 'day': 21, 'performance': 78, 'action': 2, 'script': 95, 'plot': 81, 'fact': 31, 'gets': 39, 'minutes': 71, 'doesn': 26, 'little': 59, 'interesting': 51, 'best': 9, 'real': 86, 'big': 11, 'come': 17, 'actually': 5, 'watch': 113, 'thing': 101, 'things': 102, 'love': 65, 'young': 122, 'trying': 108, 'lot': 64, 'fun': 37, 'family': 32, 'bad': 7, 'guy': 46, 'place': 79, 'screen': 94, 'away': 6, 'life': 57, 'world': 118, 'watching': 114, 'going': 42, 'comedy': 18, 'set': 97, 'worth': 120, 'girl': 40, 'makes': 68, 'long': 61, 'quite': 85, 'original': 76, 'cast': 14, 'thought': 104, 'ending': 29, 'comes': 19, 'funny': 38, 'isn': 52, 'scenes': 93, 'feel': 34, 'course': 20, 'horror': 49, 'work': 117, 'hard': 47, 'instead': 50, 'goes': 41, 'bit': 12, 'having': 48, 'true': 107}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "\n",
    "#vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", analyzer='word', max_df=0.60, min_df=0.08, max_features=5000)\n",
    "voc = vectorizer.fit(text_train)\n",
    "\n",
    "print(\"Vocabulary content:\\n {}\".format(voc.vocabulary_))\n",
    "\n",
    "criticas_a_experimentar = 100\n",
    "#text_test, label_test = particion_criticas_equilibradas(text_test,label_test,criticas_a_experimentar)\n",
    "\n",
    "\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "clf = sentiment.KNNClassifier(100)#100neigbourds\n",
    "\n",
    "clf.fit(X_train.toarray(), y_train)\n",
    "#print(X_train)\n",
    "#print((clf.vectores() != X_train))\n",
    "#print((clf.labels() != y_train))\n",
    "\n",
    "\n",
    "#Vemos que son iguales\n",
    "for index, (first, second) in enumerate(zip(y_train, clf.labels().astype(bool))):\n",
    "    if first != second:\n",
    "        print(index, second)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.670628 segundos en correr 6275 criticas\n",
      "Accuracy: 0.6873306772908366\n",
      "CPU times: user 14.6 s, sys: 67.6 ms, total: 14.7 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start_time = time.clock()\n",
    "y_pred = clf.predict(X_test.toarray())\n",
    "print (time.clock() - start_time, \"segundos en correr {} criticas\".format(len(y_pred)))\n",
    "acc = accuracy_score(y_test, y_pred.astype(bool))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "123 123\n",
      "123 123\n"
     ]
    }
   ],
   "source": [
    "import sentiment\n",
    "import numpy as np\n",
    "clf2 = sentiment.PCA(10)\n",
    "clf2.fit(X_train.toarray())\n",
    "\n",
    "\n",
    "\n",
    "M = (X_train - X_train.mean(axis=0))\n",
    "cov_matrix = M.T @ M / (M.shape[0]-1) \n",
    "\n",
    "print(cov_matrix.shape[0], cov_matrix.shape[1])\n",
    "print(clf2.cov().shape[0], clf2.cov().shape[1])\n",
    "#print(M[0, :])\n",
    "#print(cov_matrix[0,:])\n",
    "#print(clf2.cov()[0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n",
      "CPU times: user 2.82 s, sys: 12 ms, total: 2.84 s\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf2 = sentiment.PCA(10) #10 es la alfa, la cantidad de autovectores/valores que usamos\n",
    "#Si X_train es de dimension n x m, n  siendo instancias y m cantidad de variables\n",
    "#V matriz cambio de base va a ser de dimension m x alfa\n",
    "\n",
    "\n",
    "clf2.fit(X_train.toarray())#Genera y guarda matriz cambiodeBase de X_train, a partir de la matriz de covarianza.\n",
    "\n",
    "X_pda_train = clf2.transform(X_train)#Hace X_train = X_train *V(cambiodeBase generado por el fit)\n",
    "#La matriz resultante que vamos a usar en el knn tiende dimension n x alfa\n",
    "\n",
    "#Como cambiamos de base, tenemos que cambiar la base de las cosas en test para que vivan en el mismo espacio\n",
    "\n",
    "X_pda_test = clf2.transform(X_test)\n",
    "\n",
    "#dimension de X_test luego de transform = n x alfa.\n",
    "\n",
    "#Luego se sigue normalmente\n",
    "\n",
    "clf3 = sentiment.KNNClassifier(100) #hago un clf nuevo para no mezclar\n",
    "\n",
    "clf3.fit(X_pda_train, y_train)\n",
    "\n",
    "y_pred = clf3.predict(X_pda_test[0:10])\n",
    "\n",
    "acc = accuracy_score(y_test[0:10], y_pred.astype(bool))\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
