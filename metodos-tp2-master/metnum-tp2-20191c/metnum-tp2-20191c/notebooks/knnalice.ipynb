{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis con KNN\n",
    "## Clasificador en C++ ðŸ’ªðŸ’ª\n",
    "Vamos a probar a nuestro bichito\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los path al ejecutable de python 3.6 y sus librerÃ­as,\n",
    "de acuerdo al virtual env que estÃ©n corriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: no se puede crear el directorio Â«buildÂ»: El archivo ya existe\n",
      "-- The C compiler identification is GNU 4.8.4\n",
      "-- The CXX compiler identification is GNU 4.8.4\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "Release mode\n",
      "-- Found PythonInterp: /home/alicia/.pyenv/versions/3.6.5/bin/python (found version \"3.6.5\") \n",
      "-- Found PythonLibs: /home/alicia/.pyenv/versions/3.6.5/lib/libpython3.6m.a\n",
      "-- pybind11 v2.3.dev0\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "CMAKE_INSTALL_PREFIX=/home/alicia/Documentos/Metodos Numericos/TP2/metodos-tp2/metnum-tp2-20191c/metnum-tp2-20191c\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/alicia/Documentos/Metodos Numericos/TP2/metodos-tp2/metnum-tp2-20191c/metnum-tp2-20191c/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target sentiment\n",
      "\u001b[0m[ 25%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/sentiment.cpp.o\n",
      "\u001b[0m[ 50%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/knn.cpp.o\n",
      "\u001b[0m[ 75%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/pca.cpp.o\n",
      "\u001b[0m[100%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/eigen.cpp.o\n",
      "\u001b[0m\u001b[31m\u001b[1mLinking CXX shared module sentiment.cpython-36m-x86_64-linux-gnu.so\n",
      "\u001b[0m[100%] Built target sentiment\n",
      "\u001b[36mInstall the project...\n",
      "\u001b[0m-- Install configuration: \"Release\"\n",
      "-- Installing: /home/alicia/Documentos/Metodos Numericos/TP2/metodos-tp2/metnum-tp2-20191c/metnum-tp2-20191c/notebooks/sentiment.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!cd .. && git submodule init\n",
    "!cd .. && git submodule update\n",
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alicia/Documentos/Metodos Numericos/TP2/metodos-tp2/metnum-tp2-20191c/metnum-tp2-20191c/notebooks\n",
      "Python 3.6.5\n"
     ]
    }
   ],
   "source": [
    "# Verifico la correcta instalaciÃ³n. Si no falla el import estÃ¡ OK\n",
    "!pwd\n",
    "!python --version\n",
    "import sentiment\n",
    "from sentiment import entrenar\n",
    "from sentiment import generate_vocabulary\n",
    "from sentiment import entrenar_varios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "./._imdb_small.csv\n",
      "imdb_small.csv\n",
      "Cantidad de documentos: 12500\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "!cd ../data && tar -xvf *.tgz\n",
    "\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "print(\"Cantidad de documentos: {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>12469</td>\n",
       "      <td>2</td>\n",
       "      <td>12085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>test</td>\n",
       "      <td>This should have been a short film, nothing mo...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10112_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6275</td>\n",
       "      <td>2</td>\n",
       "      <td>6322</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type                                             review  label  \\\n",
       "count   12500                                              12500  12500   \n",
       "unique      2                                              12469      2   \n",
       "top      test  This should have been a short film, nothing mo...    neg   \n",
       "freq     6275                                                  2   6322   \n",
       "\n",
       "               file  \n",
       "count         12500  \n",
       "unique        12085  \n",
       "top     10112_1.txt  \n",
       "freq              2  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 6225\n",
      "Cantidad de instancias de test = 6275\n"
     ]
    }
   ],
   "source": [
    "text_train = df[df.type == 'train'][\"review\"]\n",
    "label_train = df[df.type == 'train'][\"label\"]\n",
    "text_test = df[df.type == 'test'][\"review\"]\n",
    "label_test = df[df.type == 'test'][\"label\"]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particion_criticas_equilibradas(text_train, label_train, cant_elems):\n",
    "    dict_texto = text_train.to_dict()\n",
    "    dict_label = label_train.to_dict()\n",
    "    claves_positivos = [x for x in dict_label if dict_label[x] == 'pos']\n",
    "    claves_negativos = [x for x in dict_label if dict_label[x] == 'neg']\n",
    "    posiciones_elegidas_pos = random.sample(range(0, len(claves_positivos)), int(cant_elems/2))\n",
    "    posiciones_elegidas_neg = random.sample(range(0, len(claves_negativos)), int(cant_elems/2))\n",
    "    nuevo_text_train = {}\n",
    "    nuevo_label_train = {}\n",
    "    for i in posiciones_elegidas_pos:\n",
    "        nuevo_label_train[claves_positivos[i]] = 'pos'\n",
    "        nuevo_text_train[claves_positivos[i]] = dict_texto[claves_positivos[i]]\n",
    "    for i in posiciones_elegidas_neg:\n",
    "        nuevo_label_train[claves_negativos[i]] = 'neg'\n",
    "        nuevo_text_train[claves_negativos[i]] = dict_texto[claves_negativos[i]]\n",
    "    return pd.Series(nuevo_text_train), pd.Series(nuevo_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance : 0.49493975903614457 pos 0.5050602409638554 neg\n"
     ]
    }
   ],
   "source": [
    "print(\"Class balance : {} pos {} neg\".format(\n",
    "    (label_train == 'pos').sum() / label_train.shape[0], \n",
    "    (label_train == 'neg').sum() / label_train.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6275, 1565)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary content:\n",
      " {'spoiler': 1286, 'read': 1112, 'll': 810, 'know': 755, 'horrible': 666, 'rent': 1141, 'night': 942, 'major': 842, 'results': 1146, 'created': 300, 'waste': 1496, 'building': 182, 'involved': 718, 'leading': 778, 'addition': 39, 'new': 938, 'length': 788, 'necessary': 933, 'different': 364, 'rest': 1144, 'shocking': 1224, 'effects': 417, 'result': 1145, 'right': 1155, 'seriously': 1211, 'probably': 1074, 'worst': 1543, 've': 1466, 'seen': 1201, 'year': 1556, 'low': 835, 'budget': 180, 'acting': 26, 'special': 1282, 'characters': 215, 'clichÃ£': 242, 'act': 24, 'stupid': 1327, 'predictable': 1065, 'ways': 1504, 'walking': 1487, 'dark': 321, 'looking': 819, 'cat': 201, 'falling': 486, 'catch': 202, 'small': 1257, 'room': 1164, 'films': 527, 'takes': 1358, 'possible': 1056, 'cut': 315, 'earlier': 406, 'shots': 1229, 'filming': 524, 'make': 843, 'look': 817, 'reminds': 1140, 'guys': 616, 'working': 1539, 'music': 919, 'children': 226, 'brings': 175, 'aspect': 97, 'computer': 271, 'fake': 484, 'stand': 1290, 'scene': 1182, 'giant': 587, 'suit': 1337, 'oh': 964, 'god': 595, 'supposed': 1345, 'believe': 138, 'baby': 116, 'monster': 903, 'better': 141, 'gore': 599, 'looks': 820, 'pretty': 1070, 'cool': 287, 'especially': 447, 'considering': 279, 'actors': 30, 'production': 1081, 'knew': 754, 'doing': 385, 'wasted': 1497, 'review': 1149, 'garbage': 573, '10': 0, 'dvd': 404, 'commentary': 259, 'track': 1415, 'director': 370, 'friends': 565, 'say': 1177, 'absolutely': 18, 'making': 846, 'ask': 94, 'questions': 1096, 'comments': 260, 'sub': 1329, 'human': 674, 'incredibly': 700, 'don': 386, 'want': 1489, 'kind': 751, 'starting': 1299, 'remember': 1138, 'rating': 1109, 'romantic': 1163, 'comedies': 253, 'movies': 913, 'boy': 164, 'works': 1540, 'phone': 1017, 'gay': 575, 'apartment': 76, 'woman': 1526, 'dreams': 396, 'does': 382, 'light': 794, 'dialogue': 357, 'smart': 1258, 'avoid': 110, 'copy': 289, 'actor': 29, 'asks': 96, 'understand': 1447, 'character': 214, 'viewing': 1476, 'viewer': 1474, 'missed': 893, 'great': 606, 'opportunity': 975, 'issues': 722, 'line': 800, 'far': 495, 'redeeming': 1130, 'episode': 442, 'portrayed': 1054, 'police': 1046, 'failed': 480, 'offer': 961, 'treat': 1422, 'main': 840, 'female': 514, 'child': 224, 'male': 847, 'did': 358, 'begin': 134, 'second': 1196, 'grade': 605, 'student': 1322, 'beginning': 135, 'affair': 45, 'class': 236, 'mother': 908, 'simple': 1241, 'answer': 71, 'plus': 1042, 'gave': 574, 'wasn': 1495, 'victim': 1470, 'television': 1372, 'son': 1268, 'today': 1402, 'mary': 858, 'sam': 1172, 'crime': 309, 'explained': 469, 'father': 499, 'american': 62, 'independent': 701, 'john': 733, 'society': 1263, 'political': 1047, 'career': 195, 'ended': 426, 'community': 262, 'college': 249, 'dad': 317, 'kids': 745, 'fighting': 519, 'sex': 1216, 'release': 1133, 'old': 967, 'daughter': 324, 'received': 1123, 'years': 1557, 'prison': 1073, 'numerous': 955, 'sad': 1168, 'appeared': 82, 'times': 1399, 'end': 425, 'hours': 671, 'led': 784, 'tv': 1438, 'casting': 200, 'begins': 136, 'sure': 1347, 'months': 904, 'later': 770, 'shows': 1234, 'power': 1060, 'documentary': 381, 'man': 848, 'way': 1503, 'saw': 1176, 'happened': 623, 'seeing': 1199, 'wrong': 1553, 'support': 1342, 'think': 1389, 'point': 1043, 'view': 1473, 'shown': 1233, 'utterly': 1461, 'people': 1006, 'wonderful': 1530, 'wonder': 1529, 'tell': 1373, 'actress': 31, 'played': 1033, 'wife': 1517, 'went': 1510, 'lost': 825, 'touch': 1411, 'credits': 306, 'outstanding': 982, 'superb': 1340, 'guess': 613, 'general': 577, 'feeling': 508, 'amazing': 60, 'events': 451, 'opening': 971, 'final': 528, 'worked': 1538, 'let': 789, 'fantastic': 493, 'role': 1160, 'thanks': 1381, 'called': 188, 'lack': 761, 'development': 355, 'didn': 359, 'head': 634, 'unnecessary': 1452, 'yes': 1558, 'stories': 1314, 'got': 601, 'day': 326, 'event': 450, 'change': 210, 'lives': 808, 'performance': 1009, 'lovely': 831, 'reaction': 1111, 'action': 27, 'enjoyed': 436, 'crazy': 298, 'successful': 1333, 'band': 121, '70': 11, 'decide': 333, 'try': 1432, 'start': 1297, 'playing': 1036, 'european': 449, 'hilarious': 652, 'script': 1193, 'terrific': 1379, 'spot': 1288, 'lead': 777, 'singer': 1243, 'high': 650, 'heavy': 640, 'voice': 1483, 'personality': 1014, 'problems': 1076, 'cinema': 232, 'sound': 1275, 'truly': 1429, 'awful': 115, 'plot': 1041, 'basic': 125, 'business': 185, 'fact': 478, 'merely': 880, 'excuse': 461, 'war': 1493, 'effort': 418, 'popular': 1051, 'including': 698, 'brothers': 178, 'count': 292, 'group': 610, 'gets': 584, 'standard': 1291, 'minutes': 891, 'exception': 459, 'reason': 1120, 'numbers': 954, 'doesn': 383, 'dance': 319, 'couple': 294, 'little': 805, 'stuff': 1325, 'interesting': 715, 'moment': 900, 'appears': 83, 'train': 1420, 'deep': 337, 'south': 1278, 'harry': 629, 'moments': 901, 'ray': 1110, 'camera': 190, 'tom': 1404, 'eyes': 475, 'best': 140, 'modern': 898, 'viewers': 1475, 'fans': 492, 'store': 1313, 'turn': 1434, 'secret': 1198, 'box': 163, 'number': 953, 'idea': 681, 'setting': 1214, 'rich': 1151, 'drama': 391, 'lets': 790, 'perfect': 1007, 'average': 109, 'real': 1115, 'emotions': 424, 'developed': 354, 'jokes': 735, 'big': 142, '40': 8, 'mr': 915, 'smith': 1260, 'easily': 409, 'par': 992, 'enjoy': 434, 'sorry': 1272, 'soundtrack': 1277, 'annoying': 70, 'come': 251, 'direction': 369, 'non': 944, 'honestly': 663, 'looked': 818, 'project': 1083, 'actually': 35, 'couldn': 291, 'poor': 1048, 'cinematic': 233, 'experience': 467, 'killer': 748, 'space': 1279, 'usual': 1459, 'mix': 896, 'art': 89, 'crap': 297, 'lots': 827, 'tired': 1400, 'quickly': 1098, 'definitely': 339, 'obviously': 958, 'took': 1407, 'sake': 1171, 'hate': 631, 'visually': 1482, 'attractive': 104, 'usually': 1460, 'watch': 1498, 'thing': 1387, 'series': 1210, 'early': 407, '80s': 13, 'shame': 1220, 'originally': 979, 'watched': 1500, 'classic': 237, 'deal': 329, 'things': 1388, 'stuck': 1321, 'mind': 888, 'escape': 446, 'car': 193, 'left': 786, 'love': 829, 'used': 1456, 'obvious': 957, 'mystery': 922, 'young': 1560, 'trying': 1433, 'twists': 1441, 'turns': 1437, 'surprisingly': 1352, 'adult': 42, 'excellent': 458, 'billy': 144, 'lot': 826, 'quality': 1093, 'hope': 664, 'chance': 209, 'future': 570, 'memory': 875, 'childhood': 225, 'concept': 272, 'potential': 1059, 'fun': 567, 'explanation': 470, 'force': 552, 'star': 1294, 'need': 934, 'mainly': 841, 'cold': 247, 'magic': 838, 'family': 489, 'brain': 167, 'dr': 390, 'purpose': 1090, 'laughs': 775, 'compared': 265, 'expected': 465, 'somewhat': 1267, 'particularly': 996, 'strange': 1317, 'bad': 118, 'guy': 615, 'shot': 1228, 'place': 1026, 'presence': 1067, 'screen': 1191, 'black': 148, 'plays': 1037, 'super': 1339, 'taken': 1357, 'away': 113, 'decides': 335, 'order': 976, 'live': 806, 'normal': 946, 'life': 793, 'clean': 238, 'past': 1002, 'continue': 284, 'members': 872, 'world': 1541, 'inner': 705, 'team': 1367, 'information': 704, 'innocent': 706, 'pace': 986, 'audience': 105, 'martial': 856, 'arts': 92, 'uses': 1457, 'deserves': 347, 'audiences': 106, 'performances': 1010, 'physical': 1019, 'glad': 594, 'finally': 529, 'getting': 585, 'states': 1302, 'forward': 559, 'changes': 212, 'released': 1134, 'america': 61, 'tells': 1375, 'constantly': 281, 'adventure': 44, 'said': 1170, 'mean': 865, 'watching': 1501, 'exciting': 460, 'runs': 1167, 'video': 1472, 'completely': 269, 'turned': 1435, 'problem': 1075, 'person': 1012, 'question': 1095, 'going': 597, 'comedy': 254, 'set': 1212, 'weird': 1509, 'sit': 1247, 'situations': 1250, 'worth': 1544, 'waiting': 1485, 'tried': 1424, 'talk': 1364, 'desire': 349, 'ready': 1114, 'win': 1522, 'heart': 638, 'quick': 1097, 'forget': 556, 'girl': 588, 'directors': 371, 'recently': 1125, 'days': 327, 'choice': 228, 'paul': 1004, 'means': 867, 'talent': 1361, 'shouldn': 1230, 'hand': 620, 'mess': 881, 'tony': 1406, 'mistake': 895, 'title': 1401, 'simply': 1242, 'thinking': 1390, 'makes': 845, 'sense': 1204, 'short': 1227, 'pleasant': 1038, 'motion': 909, 'picture': 1022, 'cable': 187, 'imagine': 688, 'comment': 258, 'unfortunately': 1448, 'connection': 276, 'particular': 995, 'fair': 482, 'la': 760, 'subject': 1330, 'knowledge': 757, 'house': 672, 'fairly': 483, 'felt': 513, 'player': 1034, 'long': 815, 'reminded': 1139, 'effect': 415, 'personal': 1013, 'style': 1328, 'sheer': 1222, 'genre': 580, 'various': 1465, 'detective': 353, 'producers': 1080, 'missing': 894, 'robert': 1158, 'trash': 1421, 'near': 931, 'suspense': 1355, 'mood': 905, 'quite': 1100, 'pre': 1064, 'french': 562, 'original': 978, 'ahead': 51, 'standards': 1292, 'filmed': 523, 'social': 1262, 'leaving': 783, 'subtle': 1331, 'surprise': 1349, 'gone': 598, 'suddenly': 1334, 'cast': 199, 'writing': 1551, 'theme': 1385, 'tone': 1405, 'keeping': 740, 'level': 791, 'written': 1552, 'features': 505, 'reading': 1113, 'roles': 1161, 'portray': 1052, 'complete': 268, 'touching': 1412, 'jane': 726, 'remarkable': 1137, 'romance': 1162, 'aspects': 98, 'thought': 1393, 'reasons': 1121, 'drawn': 393, 'ending': 427, 'english': 433, 'added': 38, 'england': 432, '90': 14, 'festival': 515, 'traditional': 1416, 'chinese': 227, 'local': 811, 'men': 876, 'city': 235, 'comes': 255, 'brother': 177, 'cheesy': 222, 'names': 925, 'funny': 569, 'hollywood': 660, 'famous': 490, 'master': 859, 'girlfriend': 589, 'kills': 750, 'lady': 764, 'attack': 100, 'school': 1185, 'finds': 531, 'killed': 747, 'parents': 993, 'biggest': 143, 'admit': 41, 'thriller': 1395, 'disappointing': 374, 'teenage': 1371, 'scary': 1181, 'fall': 485, 'flat': 536, 'face': 476, 'sequence': 1207, 'dramatic': 392, 'isn': 721, 'nearly': 932, 'animation': 69, 'faces': 477, 'sequences': 1208, 'creepy': 307, 'wrote': 1554, 'adaptation': 36, 'play': 1032, 'produced': 1078, 'won': 1528, 'oscar': 980, 'brilliant': 173, 'directed': 367, 'seven': 1215, 'death': 331, 'british': 176, 'author': 107, 'solid': 1265, 'taking': 1359, 'screenplay': 1192, 'material': 862, 'stage': 1289, 'create': 299, 'acts': 33, 'late': 769, 'return': 1147, 'king': 753, 'charles': 216, 'situation': 1249, 'language': 767, 'jean': 729, 'rate': 1107, 'familiar': 488, 'richard': 1152, 'villains': 1478, 'silly': 1239, 'professional': 1082, 'use': 1455, 'visual': 1481, 'white': 1515, 'expecting': 466, 'entertainment': 438, 'disappointed': 373, 'gem': 576, 'based': 124, 'lee': 785, 'marriage': 854, 'married': 855, 'plane': 1030, 'immediately': 690, 'decided': 334, 'perfectly': 1008, 'charming': 218, 'wonderfully': 1531, 'feels': 510, 'bar': 122, 'door': 387, 'hasn': 630, 'entire': 439, 'message': 882, 'impossible': 693, 'angry': 65, 'disappointment': 375, 'literally': 804, 'tears': 1368, 'dog': 384, 'sounds': 1276, 'fight': 518, 'scenes': 1184, 'rape': 1104, 'totally': 1410, 'confusing': 275, 'dumb': 403, 'shoot': 1225, 'started': 1298, 'dead': 328, 'foot': 550, 'hurt': 679, 'clear': 239, 'girls': 590, 'bring': 174, 'violence': 1479, 'cop': 288, 'violent': 1480, 'overall': 983, 'feel': 507, 'sick': 1235, 'generally': 578, 'beautiful': 129, 'pictures': 1023, 'nature': 930, 'living': 809, 'talking': 1365, 'maybe': 864, 'thats': 1382, 'women': 1527, 'conclusion': 273, 'dies': 362, 'ago': 49, 'witch': 1525, 'certainly': 208, 'clearly': 240, 'natural': 928, 'growing': 611, 'course': 295, 'die': 360, 'possibly': 1057, 'fine': 532, 'kept': 742, 'critics': 310, 'artistic': 91, 'approach': 85, 'cover': 296, 'lame': 765, 'feature': 504, '80': 12, 'teen': 1370, 'beautifully': 130, 'money': 902, 'horror': 667, 'finished': 534, 'creature': 304, 'friend': 564, 'plain': 1028, 'break': 168, 'floor': 541, 'basically': 126, 'surprised': 1350, 'peter': 1016, 'slow': 1255, 'mixed': 897, 'aren': 87, 'appreciate': 84, 'sleep': 1253, 'fell': 511, 'negative': 937, 'reviews': 1150, 'starts': 1300, 'ends': 429, 'grace': 604, 'forces': 554, 'adds': 40, 'interested': 714, 'offers': 962, 'coming': 257, 'age': 47, 'turning': 1436, 'italian': 723, 'barely': 123, 'pull': 1088, 'pathetic': 1003, 'hardly': 628, 'hero': 646, 'laughing': 774, 'drug': 400, 'military': 886, 'laughable': 772, 'gives': 592, 'include': 697, 'comic': 256, 'book': 155, 'mention': 878, 'joke': 734, 'yeah': 1555, 'alive': 55, 'kill': 746, 'work': 1537, 'kid': 744, 'lived': 807, 'sister': 1246, 'bought': 162, 'hell': 642, 'vhs': 1469, 'blood': 151, 'buy': 186, 'knows': 759, 'recall': 1122, 'certain': 207, 'consider': 277, 'using': 1458, 'wall': 1488, 'followed': 546, 'similar': 1240, 'forgotten': 557, 'unless': 1450, 'hard': 627, 'held': 641, 'longer': 816, 'terrible': 1378, 'wants': 1492, 'flick': 539, 'extreme': 472, 'bed': 132, 'wouldn': 1546, 'ok': 965, 'pure': 1089, 'tale': 1360, 'exactly': 456, 'add': 37, 'complex': 270, 'considered': 278, 'explain': 468, 'writer': 1549, 'instead': 709, 'scared': 1180, 'agent': 48, 'apart': 75, 'williams': 1520, 'decent': 332, 'job': 731, 'creating': 302, 'period': 1011, 'piece': 1024, 'musical': 920, 'allen': 56, 'ability': 15, 'write': 1548, 'case': 198, 'speak': 1280, 'points': 1045, 'outside': 981, 'share': 1221, 'curious': 314, 'able': 16, 'million': 887, 'appear': 80, 'dull': 402, 'impression': 695, 'lacks': 763, 'charm': 217, 'self': 1203, 'filmmaker': 525, 'spend': 1283, 'trailer': 1419, 'haven': 632, 'recommend': 1126, 'poorly': 1049, 'powers': 1062, '20': 6, 'normally': 947, 'personally': 1015, 'plan': 1029, 'details': 352, 'born': 159, 'unusual': 1453, 'stone': 1310, 'drugs': 401, 'needed': 935, 'mad': 837, 'says': 1179, 'murder': 917, 'flaws': 537, 'country': 293, 'loves': 833, 'americans': 63, 'bizarre': 147, 'step': 1306, 'worthy': 1545, 'killing': 749, 'humans': 675, 'hour': 670, 'obsessed': 956, 'goes': 596, 'capture': 192, 'cinematography': 234, 'green': 608, 'highly': 651, 'existence': 462, 'public': 1087, 'positive': 1055, 'asked': 95, 'loved': 830, 'flying': 542, 'came': 189, 'home': 661, 'hit': 655, 'single': 1245, 'soon': 1271, 'adults': 43, 'leave': 781, 'open': 970, 'song': 1269, 'studio': 1324, 'apparent': 77, 'deeply': 338, 'worse': 1542, 'puts': 1091, 'students': 1323, 'nicely': 941, 'favorite': 501, 'west': 1512, '13': 4, 'state': 1301, 'places': 1027, 'owner': 985, 'road': 1157, 'sign': 1237, 'told': 1403, 'theater': 1383, 'park': 994, 'showing': 1232, 'example': 457, 'slasher': 1252, 'score': 1189, 'christopher': 230, 'makers': 844, 'believable': 137, 'huge': 673, 'allow': 57, 'imagination': 687, 'sexy': 1218, 'painful': 991, 'beauty': 131, 'relationship': 1131, 'tragedy': 1417, 'saved': 1175, 'thoroughly': 1392, 'impressed': 694, 'realistic': 1117, 'moved': 911, 'focus': 543, 'version': 1467, 'dialog': 356, 'imdb': 689, 'given': 591, 'office': 963, 'body': 154, 'close': 244, 'tries': 1425, 'stay': 1304, 'follow': 545, 'picked': 1021, 'learn': 780, 'suicide': 1336, 'revenge': 1148, 'hoping': 665, 'nightmare': 943, 'type': 1442, 'bit': 145, 'fresh': 563, 'entirely': 440, 'ghost': 586, 'involving': 719, 'evil': 454, 'spirit': 1285, 'atmosphere': 99, 'lighting': 795, 'shock': 1223, 'eye': 474, 'bunch': 184, 'care': 194, 'happens': 625, 'bland': 150, 'overly': 984, 'climax': 243, 'editing': 414, 'strong': 1319, 'ideas': 682, 'delivers': 342, 'nasty': 927, 'despite': 351, 'odd': 960, 'effective': 416, 'equally': 444, 'central': 205, 'loses': 824, 'boss': 160, 'partner': 997, 'run': 1165, 'falls': 487, 'ms': 916, 'accent': 20, 'tough': 1413, 'lines': 801, 'forced': 553, 'stunning': 1326, 'pass': 1000, 'sky': 1251, 'form': 558, 'deserve': 345, 'fan': 491, 'talented': 1362, 'club': 246, 'weak': 1505, 'weren': 1511, 'ugly': 1444, 'stars': 1296, 'laugh': 771, 'paced': 987, 'fast': 498, 'david': 325, 'york': 1559, 'common': 261, 'began': 133, 'okay': 966, 'rated': 1108, 'mouth': 910, 'premise': 1066, 'century': 206, 'pointless': 1044, 'meant': 868, 'spoilers': 1287, 'honest': 662, 'moving': 914, 'note': 948, 'check': 221, 'agree': 50, 'soldiers': 1264, 'ground': 609, 'nonsense': 945, 'wild': 1518, 'apparently': 78, 'wanted': 1490, 'hey': 648, 'twice': 1439, 'boring': 158, 'half': 619, 'nice': 940, 'acted': 25, 'suspect': 1354, 'mom': 899, 'color': 250, 'having': 633, 'novel': 951, 'helps': 645, 'episodes': 443, 'help': 643, 'theatre': 1384, 'players': 1035, 'hidden': 649, 'photography': 1018, 'large': 768, 'murders': 918, 'disturbing': 379, 'aside': 93, 'fit': 535, 'follows': 548, 'william': 1519, 'list': 802, 'victims': 1471, 'jones': 736, 'fiction': 517, 'masterpiece': 860, 'comedic': 252, 'fails': 481, 'miss': 892, 'flicks': 540, 'emotional': 423, 'impact': 691, 'supposedly': 1346, 'husband': 680, 'mysterious': 921, 'happen': 622, 'recommended': 1127, 'michael': 883, 'likable': 796, 'gorgeous': 600, 'sweet': 1356, 'true': 1428, 'chemistry': 223, 'supporting': 1343, 'german': 583, 'ii': 683, 'rented': 1142, 'hands': 621, '30': 7, 'anymore': 74, 'somebody': 1266, 'storyline': 1315, 'boys': 166, 'search': 1194, 'company': 263, 'known': 758, 'collection': 248, 'week': 1508, 'date': 322, 'hot': 669, 'cartoon': 197, 'telling': 1374, 'liked': 797, 'costumes': 290, 'noticed': 950, 'rip': 1156, 'cross': 311, 'previous': 1071, 'air': 52, 'straight': 1316, 'word': 1535, 'cause': 204, 'nudity': 952, 'mentioned': 879, 'brought': 179, 'afraid': 46, 'throw': 1396, 'justice': 739, 'absurd': 19, 'clever': 241, 'leads': 779, 'heaven': 639, 'earth': 408, 'rarely': 1106, 'steal': 1305, 'post': 1058, 'essentially': 448, 'plenty': 1040, 'christmas': 229, 'party': 999, 'dancing': 320, 'memorable': 873, 'narrative': 926, 'built': 183, 'attention': 103, 'success': 1332, 'giving': 593, 'meaning': 866, 'meets': 871, 'respect': 1143, 'fully': 566, 'rare': 1105, 'convincing': 286, 'sitting': 1248, 'stop': 1311, 'fights': 520, 'knowing': 756, 'heard': 637, 'joy': 738, 'taste': 1366, 'tension': 1376, 'present': 1068, 'sadly': 1169, 'legend': 787, 'mediocre': 869, 'difficult': 365, 'managed': 850, 'history': 654, 'actions': 28, 'historical': 653, 'value': 1462, 'opens': 972, 'helped': 644, 'battle': 127, 'disney': 378, 'animal': 66, 'appeal': 79, 'running': 1166, 'game': 571, 'depth': 343, 'important': 692, 'saying': 1178, 'manner': 852, 'attempts': 102, 'dirty': 372, 'figure': 521, 'humor': 676, 'double': 388, 'machine': 836, 'mid': 884, 'doctor': 380, 'words': 1536, 'industry': 703, 'disaster': 376, 'typical': 1443, 'quiet': 1099, 'compare': 264, 'comparison': 266, 'expect': 463, 'wish': 1524, 'save': 1174, 'engaging': 431, 'london': 814, 'scientist': 1188, 'matter': 863, 'inside': 707, 'element': 420, 'surprising': 1351, 'easy': 410, 'entertaining': 437, 'compelling': 267, 'provides': 1086, 'deserved': 346, 'images': 686, 'ups': 1454, 'impressive': 696, 'songs': 1270, 'stick': 1309, 'needs': 936, 'slowly': 1256, 'heroes': 647, 'older': 968, 'reality': 1118, 'hear': 636, 'decision': 336, 'image': 685, 'humorous': 677, 'street': 1318, 'appearance': 81, 'presented': 1069, 'pop': 1050, 'government': 603, 'singing': 1244, 'talents': 1363, 'tragic': 1418, 'memories': 874, 'culture': 313, 'paid': 989, 'wait': 1484, 'brief': 171, 'sci': 1186, 'fi': 516, 'free': 561, 'opinion': 974, 'hits': 656, 'awesome': 114, 'producer': 1079, 'superior': 1341, 'aware': 112, 'race': 1101, 'slightly': 1254, 'crew': 308, 'bother': 161, '15': 5, 'water': 1502, 'summer': 1338, 'whilst': 1514, 'seemingly': 1200, 'gun': 614, 'sets': 1213, 'gang': 572, 'background': 117, 'bloody': 152, 'edge': 413, 'suppose': 1344, 'likes': 799, 'pieces': 1025, 'moral': 906, 'sat': 1173, 'technical': 1369, 'unlike': 1451, 'died': 361, 'silent': 1238, 'holds': 658, 'finish': 533, 'season': 1195, 'area': 86, 'anti': 72, 'treated': 1423, 'pay': 1005, 'middle': 885, 'dreadful': 394, 'ones': 969, 'books': 156, 'animated': 68, 'remains': 1135, 'blame': 149, 'lies': 792, 'happy': 626, 'filled': 522, 'eat': 411, 'jason': 728, 'queen': 1094, 'army': 88, 'eating': 412, 'badly': 119, 'parts': 998, 'humour': 678, 'deals': 330, 'loud': 828, 'match': 861, 'dated': 323, 'fashion': 497, 'caught': 203, 'wearing': 1506, 'spent': 1284, 'hair': 618, 'attempt': 101, 'fear': 503, 'doubt': 389, 'wooden': 1533, 'unbelievable': 1446, 'named': 924, 'wondering': 1532, 'enjoyable': 435, 'camp': 191, 'lord': 822, 'pacing': 988, 'wow': 1547, 'twist': 1440, 'joe': 732, 'portrayal': 1053, 'truth': 1431, 'red': 1129, 'recent': 1124, 'fellow': 512, 'soul': 1274, 'western': 1513, 'accurate': 23, 'hold': 657, 'food': 549, 'epic': 441, 'willing': 1521, 'wanting': 1491, 'land': 766, 'cult': 312, 'elements': 421, 'footage': 551, 'torture': 1408, 'law': 776, 'fail': 479, 'serial': 1209, 'intelligence': 710, 'shooting': 1226, 'minute': 890, 'notice': 949, 'intended': 712, 'actresses': 32, 'passion': 1001, 'soap': 1261, 'powerful': 1061, 'sort': 1273, 'smile': 1259, 'lover': 832, 'ridiculous': 1154, 'terms': 1377, 'scenery': 1183, 'magnificent': 839, 'changed': 211, 'watchable': 1499, 'scott': 1190, 'ex': 455, 'jack': 724, 'unique': 1449, 'rock': 1159, 'blue': 153, 'extremely': 473, 'inspired': 708, 'thrown': 1397, 'steve': 1308, 'everybody': 453, 'lose': 823, 'total': 1409, 'writers': 1550, 'ben': 139, 'walk': 1486, 'realize': 1119, 'filmmakers': 526, 'keeps': 741, 'showed': 1231, 'gotten': 602, 'fantasy': 494, 'actual': 34, 'content': 283, 'villain': 1477, 'younger': 1561, 'favor': 500, 'stopped': 1312, 'directing': 368, 'provide': 1085, 'clothes': 245, 'station': 1303, 'cute': 316, '12': 3, 'extra': 471, 'remake': 1136, 'damn': 318, 'contains': 282, 'ultimately': 1445, 'warning': 1494, 'control': 285, 'sees': 1202, 'drive': 398, 'cheap': 220, 'confused': 274, 'stephen': 1307, 'following': 547, 'moves': 912, 'channel': 213, 'van': 1464, 'process': 1077, 'alan': 54, 'ball': 120, 'absolute': 17, 'genius': 579, 'thank': 1380, 'pick': 1020, 'loving': 834, 'town': 1414, 'journey': 737, 'woods': 1534, 'favourite': 502, 'emotion': 422, 'direct': 366, 'church': 231, 'likely': 798, 'sexual': 1217, 'tim': 1398, 'accident': 21, 'deliver': 341, 'era': 445, 'heads': 635, 'amusing': 64, 'random': 1103, 'intriguing': 717, 'james': 725, 'suggest': 1335, 'sent': 1205, 'values': 1463, 'meet': 870, 'radio': 1102, 'leaves': 782, 'happening': 624, 'ill': 684, 'chase': 219, 'mark': 853, 'pleasure': 1039, 'themes': 1386, 'surely': 1348, 'boyfriend': 165, 'dream': 395, 'sequel': 1206, 'pain': 990, 'creative': 303, 'trip': 1426, 'stands': 1293, 'trouble': 1427, 'international': 716, '50': 9, 'featuring': 506, 'artist': 90, 'constant': 280, 'putting': 1092, 'allows': 59, 'wide': 1516, 'minor': 889, 'incredible': 699, 'zombie': 1563, 'laughed': 773, 'key': 743, 'dying': 405, 'wedding': 1507, 'credit': 305, 'ride': 1153, 'wise': 1523, 'frank': 560, 'occasionally': 959, 'indian': 702, 'greatest': 607, 'lacking': 762, 'al': 53, 'realism': 1116, 'manages': 851, 'award': 111, 'speaking': 1281, 'record': 1128, 'intelligent': 711, 'animals': 67, 'genuinely': 581, 'thinks': 1391, 'seconds': 1197, 'trust': 1430, '100': 1, '11': 2, 'versions': 1468, 'george': 582, 'eventually': 452, 'listen': 803, 'naked': 923, 'intense': 713, 'location': 812, 'feelings': 509, 'thoughts': 1394, 'hospital': 668, 'bits': 146, 'struggle': 1320, 'folks': 544, 'expectations': 464, 'brian': 170, 'difference': 363, 'efforts': 419, 'bright': 172, 'kinda': 752, 'morning': 907, 'jim': 730, 'manage': 849, 'allowed': 58, 'build': 181, 'breaks': 169, 'island': 720, 'according': 22, 'price': 1072, 'desperate': 350, 'delightful': 340, 'forever': 555, 'carry': 196, 'science': 1187, 'locations': 813, 'fascinating': 496, 'energy': 430, 'creates': 301, 'bored': 157, 'anybody': 73, 'sight': 1236, 'discover': 377, 'finding': 530, 'japanese': 727, '60': 10, 'available': 108, 'ordinary': 977, 'design': 348, 'relationships': 1132, 'described': 344, 'holes': 659, 'proves': 1084, 'funniest': 568, 'opera': 973, 'mental': 877, 'flesh': 538, 'naturally': 929, 'zombies': 1564, 'news': 939, 'dressed': 397, 'planet': 1031, 'hadn': 617, 'starring': 1295, 'endless': 428, 'loose': 821, 'shakespeare': 1219, 'practically': 1063, 'driving': 399, 'survive': 1353, 'zero': 1562, 'beat': 128, 'martin': 857, 'grown': 612}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "\n",
    "#vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", analyzer='word', max_df=0.3, min_df=0.01, max_features=5000)\n",
    "voc = vectorizer.fit(text_train)\n",
    "\n",
    "print(\"Vocabulary content:\\n {}\".format(voc.vocabulary_))\n",
    "\n",
    "criticas_a_experimentar = 1000\n",
    "text_train, label_train = particion_criticas_equilibradas(text_train,label_train,criticas_a_experimentar)\n",
    "criticas_a_experimentar = 1000\n",
    "text_test, label_test = particion_criticas_equilibradas(text_test,label_test,criticas_a_experimentar)\n",
    "\n",
    "\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1565)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "clf = sentiment.KNNClassifier(715)#100neigbourds\n",
    "\n",
    "clf.fit(X_train.toarray(), y_train)\n",
    "#print(X_train)\n",
    "#print((clf.vectores() != X_train))\n",
    "#print((clf.labels() != y_train))\n",
    "\n",
    "\n",
    "#Vemos que son iguales\n",
    "for index, (first, second) in enumerate(zip(y_train, clf.labels().astype(bool))):\n",
    "    if first != second:\n",
    "        print(index, second)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.567185 segundos en correr 6275 criticas\n",
      "Accuracy: 0.7853386454183267\n",
      "CPU times: user 1min 54s, sys: 520 ms, total: 1min 54s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start_time = time.clock()\n",
    "y_pred = clf.predict(X_test.toarray())\n",
    "print (time.clock() - start_time, \"segundos en correr {} criticas\".format(len(y_pred)))\n",
    "acc = accuracy_score(y_test, y_pred.astype(bool))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12155041  0.00149697  0.00190066 ...  0.00281581  0.00251909\n",
      "  -0.0007818 ]\n",
      " [ 0.00149697  0.11074085  0.00088758 ...  0.00641494  0.00147554\n",
      "   0.00579612]\n",
      " [ 0.00190066  0.00088758  0.10957476 ...  0.00230012  0.00107674\n",
      "   0.00052297]\n",
      " ...\n",
      " [ 0.00281581  0.00641494  0.00230012 ...  0.12994766  0.00360788\n",
      "   0.01734973]\n",
      " [ 0.00251909  0.00147554  0.00107674 ...  0.00360788  0.10981296\n",
      "   0.00230545]\n",
      " [-0.0007818   0.00579612  0.00052297 ...  0.01734973  0.00230545\n",
      "   0.12885488]]\n",
      "[[ 9.95661652e-03  3.93528124e-05  4.66173618e-05 ...  4.03264902e-04\n",
      "  -5.89024376e-05  3.32166136e-06]\n",
      " [ 3.93528124e-05  2.07206250e-03  6.56978975e-06 ...  3.11308131e-04\n",
      "   6.27870065e-05  1.28418978e-04]\n",
      " [ 4.66173618e-05  6.56978975e-06  2.18500574e-03 ...  1.22078239e-04\n",
      "   6.80120728e-05  4.35441912e-05]\n",
      " ...\n",
      " [ 4.03264902e-04  3.11308131e-04  1.22078239e-04 ...  7.97942845e-03\n",
      "   2.16268891e-04  6.53611672e-04]\n",
      " [-5.89024376e-05  6.27870065e-05  6.80120728e-05 ...  2.16268891e-04\n",
      "   2.73887122e-03 -5.04943238e-05]\n",
      " [ 3.32166136e-06  1.28418978e-04  4.35441912e-05 ...  6.53611672e-04\n",
      "  -5.04943238e-05  7.69291192e-03]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, n_neighbors, metric='l2'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def _predict_row(self, row):\n",
    "        A = np.argsort(np.sum((np.square(self.X-row)), axis=1))        \n",
    "        \n",
    "        k = np.zeros(self.n_neighbors)\n",
    "        for i in range(k.shape[0]):\n",
    "            k[i] = self.y[A[i]]\n",
    "        \n",
    "        k = np.bincount(k.astype(int))        \n",
    "        \n",
    "\n",
    "        return np.argmax(k)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        ret = np.zeros(X.shape[0])\n",
    "        for k, row in enumerate(X):\n",
    "            ret[k] = self._predict_row(row)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "M = (X_train - X_train.mean(axis=0))\n",
    "\n",
    "cov_matrix = M.T @ M / (M.shape[0]-1) \n",
    "w, V = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# A veces aparecen nÃºmeros complejos acÃ¡. Los descartamos\n",
    "w = np.real(w)\n",
    "V = np.real(V)\n",
    "\n",
    "X_pca_train = X_train @ V[:, :30]\n",
    "X_pca_test = X_test @ V[:, :30]\n",
    "\n",
    "clf = KNNClassifier(715)\n",
    "clf.fit(X_pca_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5064541832669323\n",
      "CPU times: user 40.2 s, sys: 4 ms, total: 40.2 s\n",
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_pca_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6956175298804781\n",
      "CPU times: user 5.6 s, sys: 824 ms, total: 6.43 s\n",
      "Wall time: 3.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(30)\n",
    "pca.fit(X_train.toarray())\n",
    "X_train_posta = pca.transform(X_train.toarray())\n",
    "X_test_posta = pca.transform(X_test.toarray())\n",
    "\n",
    "clf3 = sentiment.KNNClassifier(715) #hago un clf nuevo para no mezclar\n",
    "clf3.fit(X_train_posta, y_train)\n",
    "y_pred = clf3.predict(X_test_posta)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred.astype(bool))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 4 ms, total: 24 ms\n",
      "Wall time: 24.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf2 = sentiment.PCA(10) #10 es la alfa, la cantidad de autovectores/valores que usamos\n",
    "#Si X_train es de dimension n x m, n  siendo instancias y m cantidad de variables\n",
    "#V matriz cambio de base va a ser de dimension m x alfa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 908 ms, total: 1min 28s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf2.fit(X_train.toarray(), 1000, 10)#Genera y guarda matriz cambiodeBase de X_train, a partir de la matriz de covarianza.\n",
    "X_pda_train = clf2.transform(X_train.toarray())#Hace X_train = X_train *V(cambiodeBase generado por el fit)\n",
    "#La matriz resultante que vamos a usar en el knn tiende dimension n x alfa\n",
    "#Como cambiamos de base, tenemos que cambiar la base de las cosas en test para que vivan en el mismo espacio\n",
    "X_pda_test = clf2.transform(X_test.toarray())\n",
    "#Luego se sigue normalmente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6162549800796813\n",
      "CPU times: user 1.69 s, sys: 20 ms, total: 1.71 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf3 = sentiment.KNNClassifier(715) #hago un clf nuevo para no mezclar\n",
    "clf3.fit(X_pda_train, y_train)\n",
    "y_pred = clf3.predict(X_pda_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred.astype(bool))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003333333333333333\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.03\n",
      "0.035\n",
      "0.04\n",
      "0.045\n",
      "Accuracy: 0.7595219123505976\n",
      "1025.74343 segundos en correr 6275 criticas\n",
      "CPU times: user 17min 2s, sys: 3.72 s, total: 17min 5s\n",
      "Wall time: 17min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start_time = time.clock()\n",
    "vecinos = [1] + [15*x for x in range(1,10)]\n",
    "with open(\"positibidad_01.txt\", \"w\") as f:\n",
    "    for k in vecinos:\n",
    "        clf = sentiment.KNNClassifier(k)\n",
    "        clf.fit(X_train.toarray(), y_train)\n",
    "        y_pred = clf.predict(X_test.toarray())\n",
    "        for elem in y_pred:\n",
    "            f.write(\" {}\".format(int(elem)))\n",
    "        print(k/3000)\n",
    "acc = accuracy_score(y_test, y_pred.astype(bool))\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print (time.clock() - start_time, \"segundos en correr {} criticas\".format(len(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6231075697211156\n",
      "Accuracy: 0.575776397515528\n",
      "Accuracy: 0.897965773329028\n",
      "2759.7374720000003 segundos en correr 6275 criticas\n",
      "CPU times: user 45min 47s, sys: 12.4 s, total: 45min 59s\n",
      "Wall time: 45min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import time\n",
    "\n",
    "start_time = time.clock()\n",
    "alpha = 80\n",
    "fprogreso = open(\"progreso_pda_iter2_01.txt\", \"w\")\n",
    "clf = sentiment.PCA(alpha)\n",
    "with open(\"positividad_pda_iter2_01.txt\", \"w\") as f:\n",
    "    for num in range(100, 2000, 250):\n",
    "        clf.fit(X_train.toarray(), num, alpha)\n",
    "        X_pda_train = clf.transform(X_train.toarray())\n",
    "        X_pda_test = clf.transform(X_test.toarray())\n",
    "        clf3 = sentiment.KNNClassifier(100) \n",
    "        clf3.fit(X_pda_train, y_train)\n",
    "        y_pred = clf3.predict(X_pda_test)\n",
    "        for elem in y_pred:\n",
    "            f.write(\" {}\".format(int(elem)))\n",
    "        fprogreso.write(\" {}\".format(int(num)))\n",
    "fprogreso.close()    \n",
    "acc = accuracy_score(y_test, y_pred.astype(bool))\n",
    "prec = precision_score(y_test, y_pred.astype(bool))\n",
    "recall = recall_score(y_test, y_pred.astype(bool))\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print(\"Accuracy: {}\".format(prec))\n",
    "print(\"Accuracy: {}\".format(recall))\n",
    "print (time.clock() - start_time, \"segundos en correr {} criticas\".format(len(y_pred)))            \n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import sentiment\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "start_time = time.clock\n",
    "print(type(start_time.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 52s, sys: 1.81 s, total: 3min 54s\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import sentiment\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "start_time = time.clock()\n",
    "alpha = 100\n",
    "f= open(\"samples_size100_time_alpha\", \"w\")\n",
    "for alpha in range (10,100,10 )\n",
    "    start_time = time.clock()\n",
    "    num_iteraciones = 500\n",
    "    clf = sentiment.PCA(alpha)\n",
    "    clf.fit(X_train.toarray(), num_iteraciones, alpha)\n",
    "    f.write(\" {}\".format(time.clock() - start_time))\n",
    "f.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6409561752988048\n",
      "Precision: 0.5842988413903316\n",
      "Recall: 0.9444623829512432\n",
      "396.561365 segundos en correr 6275 criticas\n"
     ]
    }
   ],
   "source": [
    "fprogreso = open(\"progreso_pda_alpha_01.txt\", \"w\")\n",
    "with open(\"positividad_pda_alpha_01.txt\", \"w\") as f:\n",
    "    for n in range(2, 100, 5):        \n",
    "        clf.fit(X_train.toarray(), num_iteraciones, n)\n",
    "        X_pda_train = clf.transform(X_train.toarray())\n",
    "        X_pda_test = clf.transform(X_test.toarray())\n",
    "        clf3 = sentiment.KNNClassifier(715) \n",
    "        clf3.fit(X_pda_train, y_train)\n",
    "        y_pred = clf3.predict(X_pda_test)                \n",
    "        for elem in y_pred:            \n",
    "            f.write(\" {}\".format(int(elem)))        \n",
    "        fprogreso.write(\" {}\".format(int(n)))\n",
    "    f.close()\n",
    "fprogreso.close()    \n",
    "acc = accuracy_score(y_test, y_pred.astype(bool))\n",
    "prec = precision_score(y_test, y_pred.astype(bool))\n",
    "recall = recall_score(y_test, y_pred.astype(bool))\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print(\"Precision: {}\".format(prec))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "print (time.clock() - start_time, \"segundos en correr {} criticas\".format(len(y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = [x*2 for x in range(1,50)]\n",
    "with open(\"positividad_real_no_fake2.txt\", \"w\") as f:\n",
    "    for n in n_components:             \n",
    "        for elem in y_test:            \n",
    "            f.write(\" {}\".format(int(elem)))        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 37s, sys: 3.44 s, total: 6min 40s\n",
      "Wall time: 6min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import sentiment\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "start_time = time.clock()\n",
    "alpha = 80\n",
    "num_iteraciones = 1000\n",
    "clf = sentiment.PCA(alpha)\n",
    "clf.fit(X_train.toarray(), num_iteraciones, alpha)\n",
    "\n",
    "clf.fit(X_train.toarray(), num_iteraciones, 10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.97686781e+00  4.19527018e-01  1.07058507e+00 ... -3.29344247e-01\n",
      "  -4.96230906e-01 -4.35108291e-02]\n",
      " [-2.46798871e+00  5.29457849e-01  5.15272826e-01 ... -1.29535469e+00\n",
      "   4.69122471e-01 -2.69031824e-01]\n",
      " [-2.63618079e-01 -3.37334380e-03 -1.28825474e-01 ...  6.99147296e-02\n",
      "  -1.06016402e-01 -5.07839531e-02]\n",
      " ...\n",
      " [-4.41264524e+00 -1.01503753e+00 -1.16829444e+00 ...  1.03958805e+00\n",
      "  -6.85012169e-01  2.65175893e-02]\n",
      " [-1.13784782e+00  2.66447186e-01 -1.09570287e-01 ... -1.35121219e-01\n",
      "   6.13693386e-02  4.69386744e-01]\n",
      " [-3.98783282e+00  8.12062420e-01 -1.53235161e+00 ...  2.02658754e-01\n",
      "  -8.23122544e-01 -3.21244628e-01]]\n",
      "(6275, 20)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train.toarray(), num_iteraciones, 20)\n",
    "X_pdatrain =clf.transform(X_train.toarray())\n",
    "X_pdatest = clf.transform(X_test.toarray())\n",
    "print(X_pdatest)\n",
    "print(X_pdatest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "clf3 = sentiment.KNNClassifier(715) \n",
    "clf3.fit(X_pda_train, y_train)\n",
    "y_pred = clf3.predict(X_pda_test) \n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 140 ms, sys: 80 ms, total: 220 ms\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train.toarray(), num_iteraciones, 20)\n",
    "X_pdatrain =clf.transform(X_train.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6225, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_pdatrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
